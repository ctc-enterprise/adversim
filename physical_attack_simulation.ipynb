{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn, fasterrcnn_mobilenet_v3_large_fpn\n",
        "from torchvision.transforms import functional as F\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "8_cdGgNOAjNj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Global Configuration ---\n",
        "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "OUTPUT_DIR = \"advanced_results\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# COCO Class mapping for readability\n",
        "COCO_INSTANCE_CATEGORY_NAMES = [\n",
        "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
        "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
        "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
        "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
        "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
        "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
        "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A',\n",
        "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
        "]"
      ],
      "metadata": {
        "id": "nkI1nkxwAlVC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- 1. Infrastructure: Model & Image Loading ---\n",
        "\n",
        "def get_model(model_name='resnet50'):\n",
        "    print(f\"Loading {model_name} model on {DEVICE}...\")\n",
        "    if model_name == 'resnet50':\n",
        "        model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    elif model_name == 'mobilenet':\n",
        "        model = fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def get_image():\n",
        "    # A standard image with a person and a car usually works best for these demos\n",
        "    url = \"https://raw.githubusercontent.com/pytorch/hub/master/images/dog.jpg\"\n",
        "    # Let's use a street scene if possible, but the dog image is reliable for the 'Dog' class.\n",
        "    # To demonstrate miscategorization (Dog -> Car) and vanishing (Dog -> nothing).\n",
        "    print(f\"Downloading sample image from {url}...\")\n",
        "    response = requests.get(url)\n",
        "    img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "    return img\n",
        "\n",
        "def preprocess(image):\n",
        "    return F.to_tensor(image).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "def visualize(img_tensor, model, title, save_path, threshold=0.5):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        preds = model(img_tensor)[0]\n",
        "\n",
        "    img_np = img_tensor.squeeze().cpu().permute(1, 2, 0).detach().numpy()\n",
        "    img_np = np.clip(img_np, 0, 1)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(img_np)\n",
        "    ax = plt.gca()\n",
        "\n",
        "    found_objects = []\n",
        "\n",
        "    for box, label, score in zip(preds['boxes'], preds['labels'], preds['scores']):\n",
        "        if score > threshold:\n",
        "            box = box.cpu().numpy()\n",
        "            label_name = COCO_INSTANCE_CATEGORY_NAMES[label]\n",
        "            found_objects.append(f\"{label_name} ({score:.2f})\")\n",
        "\n",
        "            # Color code: Green for Person, Blue for Car, Red for Dog, etc.\n",
        "            color = 'red'\n",
        "            if label == 1: color = 'green' # Person\n",
        "            if label == 3: color = 'blue'  # Car\n",
        "\n",
        "            rect = plt.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1],\n",
        "                                 fill=False, color=color, linewidth=3)\n",
        "            ax.add_patch(rect)\n",
        "            plt.text(box[0], box[1], f\"{label_name}: {score:.2f}\",\n",
        "                     color='white', fontsize=10, backgroundcolor=color)\n",
        "\n",
        "    plt.title(f\"{title}\\nDetections: {', '.join(found_objects)}\")\n",
        "    plt.axis('off')\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, bbox_inches='tight')\n",
        "        print(f\"Saved: {save_path}\")\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "uwKetTmsAnwK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. The Core: EOT & Patch Generator ---\n",
        "\n",
        "class PhysicalAttackSimulator:\n",
        "    def __init__(self, model, img_tensor, patch_size_ratio=0.2):\n",
        "        self.model = model\n",
        "        self.img_tensor = img_tensor.clone()\n",
        "        _, _, h, w = img_tensor.shape\n",
        "\n",
        "        # Patch configuration\n",
        "        self.patch_size = int(min(h, w) * patch_size_ratio)\n",
        "        self.patch = torch.rand((3, self.patch_size, self.patch_size),\n",
        "                                device=DEVICE, requires_grad=True)\n",
        "\n",
        "        # EOT Augmentations (Simulate physical world distortions)\n",
        "        self.augmentations = torch.nn.Sequential(\n",
        "            T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.1),\n",
        "            T.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.8, 1.2), shear=10)\n",
        "        )\n",
        "\n",
        "    def get_patch_overlay(self, base_img, patch_tensor, target_box=None, random_pos=False):\n",
        "        \"\"\"\n",
        "        Applies the patch to the image with EOT transformations.\n",
        "        target_box: [x1, y1, x2, y2] to center the patch on.\n",
        "        random_pos: If True, place anywhere (for fabrication).\n",
        "        \"\"\"\n",
        "        # 1. Apply Physical Distortions to the Patch (EOT)\n",
        "        # We process the patch independently before placing it\n",
        "        aug_patch = self.augmentations(patch_tensor)\n",
        "\n",
        "        # 2. Determine Location\n",
        "        _, _, h, w = base_img.shape\n",
        "        ph, pw = self.patch_size, self.patch_size\n",
        "\n",
        "        if random_pos:\n",
        "            x = random.randint(0, w - pw)\n",
        "            y = random.randint(0, h - ph)\n",
        "        elif target_box is not None:\n",
        "            # Center on target box\n",
        "            bx, by, bx2, by2 = target_box\n",
        "            bw, bh = bx2 - bx, by2 - by\n",
        "            x = int(bx + bw/2 - pw/2)\n",
        "            y = int(by + bh/2 - ph/2)\n",
        "            # Clamp to image bounds\n",
        "            x = max(0, min(x, w - pw))\n",
        "            y = max(0, min(y, h - ph))\n",
        "        else:\n",
        "            x, y = 0, 0 # Default top-left\n",
        "\n",
        "        # 3. Paste Patch\n",
        "        patched_img = base_img.clone()\n",
        "        patched_img[:, :, y:y+ph, x:x+pw] = aug_patch\n",
        "        return patched_img\n",
        "\n",
        "    def run_attack(self, mode='vanishing', target_label=None, epochs=30, learning_rate=0.05):\n",
        "        \"\"\"\n",
        "        Main optimization loop for all 3 attack modes.\n",
        "        Modes: 'vanishing', 'miscategorization', 'fabrication'\n",
        "        \"\"\"\n",
        "        print(f\"\\n--- Running Attack: {mode.upper()} ---\")\n",
        "\n",
        "        # Reset patch for new attack\n",
        "        self.patch.data = torch.rand_like(self.patch)\n",
        "        optimizer = torch.optim.Adam([self.patch], lr=learning_rate)\n",
        "\n",
        "        # Get Ground Truth (or pseudo-ground truth) from clean image\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            gt_preds = self.model(self.img_tensor)[0]\n",
        "\n",
        "        # Select the most confident object as the victim\n",
        "        if len(gt_preds['boxes']) == 0:\n",
        "            print(\"No objects found to attack.\")\n",
        "            return self.img_tensor\n",
        "\n",
        "        victim_idx = 0 # Assume top score is the target\n",
        "        victim_box = gt_preds['boxes'][victim_idx]\n",
        "        victim_label = gt_preds['labels'][victim_idx]\n",
        "\n",
        "        print(f\"Targeting Object: {COCO_INSTANCE_CATEGORY_NAMES[victim_label]} at {victim_box.cpu().numpy()}\")\n",
        "\n",
        "        for epoch in tqdm(range(epochs)):\n",
        "            total_loss = 0\n",
        "\n",
        "            # EOT Batch: Average gradients over multiple random transformations\n",
        "            for _ in range(5):\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # A. Apply Patch based on Mode\n",
        "                if mode == 'fabrication':\n",
        "                    # Place patch in random BACKGROUND locations\n",
        "                    # (Simplified: just random location, hoping to spawn a box)\n",
        "                    patched_img = self.get_patch_overlay(self.img_tensor, self.patch, random_pos=True)\n",
        "                else:\n",
        "                    # Place patch ON the victim object\n",
        "                    patched_img = self.get_patch_overlay(self.img_tensor, self.patch, target_box=victim_box)\n",
        "\n",
        "                # B. Forward Pass\n",
        "                # We need gradients, so we use training mode logic or manual loss calc\n",
        "                # FasterRCNN allows passing targets in train mode to compute loss automatically\n",
        "                self.model.train()\n",
        "\n",
        "                # Define Targets based on Mode\n",
        "                if mode == 'vanishing':\n",
        "                    # We want to confuse the model.\n",
        "                    # We provide the TRUE label, but we MINIMIZE the negative loss?\n",
        "                    # No, standard attack maximizes the Loss(Prediction, True Label).\n",
        "\n",
        "                    # Trick: Pass the GROUND TRUTH. The model computes loss. We maximize it.\n",
        "                    targets = [{\n",
        "                        'boxes': victim_box.unsqueeze(0),\n",
        "                        'labels': victim_label.unsqueeze(0)\n",
        "                    }]\n",
        "                    loss_dict = self.model(patched_img, targets)\n",
        "                    # Maximize classifier loss and regression loss to break detection\n",
        "                    loss = sum(loss for loss in loss_dict.values())\n",
        "                    # Gradient Descent minimizes, so we negate to maximize error\n",
        "                    loss = -loss\n",
        "\n",
        "                elif mode == 'miscategorization':\n",
        "                    # We want the model to predict TARGET_LABEL instead of True Label.\n",
        "                    # We minimize Loss(Prediction, Target Label).\n",
        "                    if target_label is None: raise ValueError(\"Need target_label for miscategorization\")\n",
        "\n",
        "                    targets = [{\n",
        "                        'boxes': victim_box.unsqueeze(0),\n",
        "                        'labels': torch.tensor([target_label], device=DEVICE)\n",
        "                    }]\n",
        "                    loss_dict = self.model(patched_img, targets)\n",
        "                    # Standard minimization of loss towards the fake label\n",
        "                    loss = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "                elif mode == 'fabrication':\n",
        "                    # We want the model to detect the patch as TARGET_LABEL.\n",
        "                    # Since we don't know exactly where the box will be proposed,\n",
        "                    # we essentially treat the patch location as the ground truth box.\n",
        "\n",
        "                    # Note: We need to know where we put the patch in this specific EOT iteration\n",
        "                    # The get_patch_overlay helper was stateless, so for fabrication we need to be careful.\n",
        "                    # For prototype simplicity: logic is inside the EOT loop:\n",
        "\n",
        "                    # Re-do patch placement to capture coordinates\n",
        "                    _, _, h, w = self.img_tensor.shape\n",
        "                    ph, pw = self.patch_size, self.patch_size\n",
        "                    rx = random.randint(0, w - pw)\n",
        "                    ry = random.randint(0, h - ph)\n",
        "\n",
        "                    aug_patch = self.augmentations(self.patch)\n",
        "                    p_img = self.img_tensor.clone()\n",
        "                    p_img[:, :, ry:ry+ph, rx:rx+pw] = aug_patch\n",
        "\n",
        "                    # Target: We WANT a box here with target_label\n",
        "                    fake_box = torch.tensor([[rx, ry, rx+pw, ry+ph]], dtype=torch.float32, device=DEVICE)\n",
        "                    targets = [{\n",
        "                        'boxes': fake_box,\n",
        "                        'labels': torch.tensor([target_label], device=DEVICE)\n",
        "                    }]\n",
        "\n",
        "                    loss_dict = self.model(p_img, targets)\n",
        "                    loss = sum(loss for loss in loss_dict.values())\n",
        "                    patched_img = p_img # Update reference for next steps\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # Clamp patch to valid image range\n",
        "                self.patch.data.clamp_(0, 1)\n",
        "\n",
        "        # Return the best final image (no random augmentations for display)\n",
        "        if mode == 'fabrication':\n",
        "            # Place in empty space for final result\n",
        "            final_img = self.get_patch_overlay(self.img_tensor, self.patch, random_pos=True)\n",
        "        else:\n",
        "            final_img = self.get_patch_overlay(self.img_tensor, self.patch, target_box=victim_box)\n",
        "\n",
        "        return final_img"
      ],
      "metadata": {
        "id": "F3c3rG7bArDS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Execution Logic ---\n",
        "\n",
        "def main():\n",
        "    # 1. Setup\n",
        "    model = get_model('resnet50') # Can swap to 'mobilenet'\n",
        "    img_pil = get_image()\n",
        "    img_tensor = preprocess(img_pil)\n",
        "\n",
        "    # 2. Baseline\n",
        "    print(\"Generating Baseline...\")\n",
        "    visualize(img_tensor, model, \"Baseline (Clean)\", os.path.join(OUTPUT_DIR, \"0_baseline.png\"))\n",
        "\n",
        "    attacker = PhysicalAttackSimulator(model, img_tensor)\n",
        "\n",
        "    # 3. Attack 1: Vanishing (Hiding the Dog)\n",
        "    # The patch tries to maximize loss on the 'Dog' class\n",
        "    print(\"Generating Vanishing Attack...\")\n",
        "    adv_img_vanish = attacker.run_attack(mode='vanishing', epochs=30)\n",
        "    visualize(adv_img_vanish, model, \"Vanishing Attack (Object Hiding)\",\n",
        "              os.path.join(OUTPUT_DIR, \"1_vanishing_attack.png\"))\n",
        "\n",
        "    # 4. Attack 2: Miscategorization (Dog -> Car)\n",
        "    # COCO Class 3 is 'Car'. We want the Dog to be detected as a Car.\n",
        "    print(\"Generating Miscategorization Attack (Target: Car)...\")\n",
        "    adv_img_mis = attacker.run_attack(mode='miscategorization', target_label=3, epochs=40)\n",
        "    visualize(adv_img_mis, model, \"Miscategorization (Dog -> Car)\",\n",
        "              os.path.join(OUTPUT_DIR, \"2_miscategorization_attack.png\"))\n",
        "\n",
        "    # 5. Attack 3: Fabrication (Hallucinating a Toaster)\n",
        "    # COCO Class 80 is 'Toaster'. We want a Toaster to appear in the background.\n",
        "    print(\"Generating Fabrication Attack (Target: Toaster)...\")\n",
        "    adv_img_fab = attacker.run_attack(mode='fabrication', target_label=80, epochs=40)\n",
        "    visualize(adv_img_fab, model, \"Fabrication (Phantom Toaster)\",\n",
        "              os.path.join(OUTPUT_DIR, \"3_fabrication_attack.png\"), threshold=0.3)\n",
        "\n",
        "    print(f\"\\nSimulation Complete. Results saved to {OUTPUT_DIR}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading resnet50 model on cuda...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading sample image from https://raw.githubusercontent.com/pytorch/hub/master/images/dog.jpg...\n",
            "Generating Baseline...\n",
            "Saved: advanced_results/0_baseline.png\n",
            "Generating Vanishing Attack...\n",
            "\n",
            "--- Running Attack: VANISHING ---\n",
            "Targeting Object: dog at [ 137.8407    67.79935 1386.9038  1172.8246 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [00:39<00:00,  1.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: advanced_results/1_vanishing_attack.png\n",
            "Generating Miscategorization Attack (Target: Car)...\n",
            "\n",
            "--- Running Attack: MISCATEGORIZATION ---\n",
            "Targeting Object: dog at [ 137.8407    67.79935 1386.9038  1172.8246 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:51<00:00,  1.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: advanced_results/2_miscategorization_attack.png\n",
            "Generating Fabrication Attack (Target: Toaster)...\n",
            "\n",
            "--- Running Attack: FABRICATION ---\n",
            "Targeting Object: dog at [ 137.8407    67.79935 1386.9038  1172.8246 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:52<00:00,  1.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: advanced_results/3_fabrication_attack.png\n",
            "\n",
            "Simulation Complete. Results saved to advanced_results\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9WxovUOAcIU",
        "outputId": "119d6e06-1ffd-4bc7-ad6b-caa43f8a8d3f"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}